{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 1370\n"
     ]
    }
   ],
   "source": [
    "# Opening both face and non-faced images \n",
    "face_images = glob.glob(\"data/faces/**.jpg\")\n",
    "non_face_images = glob.glob(\"data/non-faces/**.jpg\")\n",
    "print(len(face_images), len(non_face_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_face_images = []\n",
    "read_non_face_images = []\n",
    "\n",
    "for i in range(len(face_images)):\n",
    "    single_face_image = cv2.imread(face_images[i])\n",
    "    single_face_image = cv2.resize(single_face_image, (224, 224))\n",
    "    read_face_images.append(single_face_image)\n",
    "    \n",
    "\n",
    "for i in range(len(non_face_images)):\n",
    "    non_single_face_image = cv2.imread(non_face_images[i])\n",
    "    non_single_face_image = cv2.resize(non_single_face_image, (224, 224))\n",
    "    read_non_face_images.append(non_single_face_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "image_shape = read_non_face_images[0].shape\n",
    "print(image_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create clone of image and rotate for more data\n",
    "def image_rotation(img_list):\n",
    "    for i in range(len(img_list)):\n",
    "        rand_number = random.randint(45, 180) \n",
    "        img = img_list[i]\n",
    "        cloned_image = img.copy()\n",
    "        M = cv2.getRotationMatrix2D((112,112), rand_number, 1)\n",
    "        dst = cv2.warpAffine(img, M, (112,112))\n",
    "        img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "def add_noise(img_list):\n",
    "    for i in range(len(img_list)):\n",
    "        img = img_list[i]\n",
    "        cloned_image = img.copy()\n",
    "        noisy_image = skimage.util.random_noise(cloned_image, mode='gaussian', seed=None, clip=True) \n",
    "        img_list.append(np.asarray(noisy_image, dtype=\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import rotate\n",
    "def sharpen_img(img_list):\n",
    "    for i in range(len(img_list)):\n",
    "        img = img_list[i]\n",
    "        cloned_image = img.copy()\n",
    "        gb = cv2.GaussianBlur(cloned_image, (5,5), 20.0)\n",
    "        img_list.append(cv2.addWeighted(img, 2, gb, -1, 0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 10960\n"
     ]
    }
   ],
   "source": [
    "def augment_all(img_list):\n",
    "    image_rotation(img_list)\n",
    "    add_noise(img_list)\n",
    "    sharpen_img(img_list)\n",
    "    \n",
    "augment_all(read_face_images)\n",
    "augment_all(read_non_face_images)\n",
    "\n",
    "print(len(read_face_images), len(read_non_face_images))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concactenate the Images together\n",
    "features_data = np.vstack((read_face_images, read_non_face_images)).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14560\n"
     ]
    }
   ],
   "source": [
    "#Creating labels for the images\n",
    "labels = np.hstack((np.ones(len(read_face_images)), np.zeros(len(read_non_face_images))))\n",
    "print(len(features_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "random.shuffle(features_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_data, labels, test_size=0, random_state = np.random.randint(0, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Defining Architecture\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Architecture of the Convolutional Neural Network Begins Here\n",
    "#Architecture comes from MobileNet Paper\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def mobileNet(x):\n",
    "    # Hyperparameters\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    stride = [1, 1, 1, 1]\n",
    "    stride_2 = [1, 2, 2, 1]\n",
    "    dropout = 0.5\n",
    "    \n",
    "    #Layer Input = 224, 224, 3 Output = \n",
    "    weights_0 = tf.Variable(tf.truncated_normal(shape= (3, 3, 3, 32), mean= mu, stddev= sigma))\n",
    "    bias_0 = tf.Variable(tf.zeros(32))\n",
    "    \n",
    "    conv_0 = tf.nn.conv2d(x, weights_0, stride_2, padding= 'VALID') + bias_0\n",
    "    \n",
    "    #Activation\n",
    "    conv_0 = tf.nn.relu(conv_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
